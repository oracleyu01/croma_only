# ëŒ€í™”í˜• ì³‡ë´‡ ì• í”Œë¦¬ì¼€ì´ì…˜ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import streamlit as st
import json
import chromadb
from chromadb.utils import embedding_functions
from openai import OpenAI
import re

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë¶€ë™ì‚° ê°€ê²© ë¶„ì„ AI ì—ì´ì „íŠ¸", page_icon="ğŸ ")

# OpenAI API í‚¤ ê°€ì ¸ì˜¤ê¸°
def get_api_key():
    """Streamlit secrets ë˜ëŠ” ì‚¬ì´ë“œë°” ì…ë ¥ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°"""
    # 1. Streamlit secretsì—ì„œ ë¨¼ì € í™•ì¸
    try:
        return st.secrets["OPENAI_API_KEY"]
    except:
        # 2. secretsê°€ ì—†ìœ¼ë©´ ì‚¬ì´ë“œë°” ì…ë ¥ ì‚¬ìš©
        return st.sidebar.text_input(
            "OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”", 
            type="password",
            help="Streamlit Cloudì—ì„œëŠ” Settings > Secretsì—ì„œ OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”"
        )

# ì‚¬ì´ë“œë°” ì„¤ì •
st.sidebar.title("ì„¤ì •")
api_key = get_api_key()

# API í‚¤ ìƒíƒœ í‘œì‹œ
if api_key and api_key.startswith("sk-"):
    st.sidebar.success("âœ… API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤")
else:
    st.sidebar.warning("âš ï¸ API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”")
    with st.sidebar.expander("API í‚¤ ì„¤ì • ë°©ë²•"):
        st.write("""
        **Streamlit Cloud:**
        1. App settings â†’ Secrets í´ë¦­
        2. ë‹¤ìŒ ë‚´ìš© ì¶”ê°€:
        ```
        OPENAI_API_KEY = "sk-..."
        ```
        
        **ë¡œì»¬ í™˜ê²½:**
        1. `.streamlit/secrets.toml` íŒŒì¼ ìƒì„±
        2. ìœ„ì™€ ê°™ì€ ë‚´ìš© ì¶”ê°€
        """)

# ì»¬ë ‰ì…˜ ì´ë¦„ ì…ë ¥ (ì‚¬ì´ë“œë°”)
collection_name = st.sidebar.text_input("ì‚¬ìš©í•  ì»¬ë ‰ì…˜ ì´ë¦„", value="real_estate_prices_20250511")

# í˜ì´ì§€ ì œëª©
st.title("ğŸ  ë¶€ë™ì‚° ê°€ê²© ë¶„ì„ AI ë°ì´í„° ë¶„ì„ê°€")
st.write("ë‰´ìŠ¤ ê¸°ì‚¬ ë° ë³´ê³ ì„œì—ì„œ ìˆ˜ì§‘í•œ ë¶€ë™ì‚° ê°€ê²© ë°ì´í„°ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”.")

# ì´ë¯¸ì§€ í‘œì‹œ (ì˜µì…˜)
try:
    st.image("realestate.png", use_container_width=True)
except:
    # ì´ë¯¸ì§€ê°€ ì—†ì–´ë„ ì•±ì´ ì‘ë™í•˜ë„ë¡ ì²˜ë¦¬
    pass

# ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
@st.cache_resource
def init_chroma_client():
    # ë©”ëª¨ë¦¬ ëª¨ë“œë¡œ ì‚¬ìš© (ë” ê°„ë‹¨!)
    return chromadb.Client()

# ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ (ë°ëª¨ìš©)
def load_sample_data(client):
    """ë°ëª¨ë¥¼ ìœ„í•œ ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ"""
    try:
        collection = client.create_collection(
            name="real_estate_prices_20250511",
            metadata={"description": "ë¶€ë™ì‚° ê°€ê²© ë¶„ì„ ë°ì´í„°"}
        )
        
        # ìƒ˜í”Œ ë°ì´í„°
        sample_docs = [
            {
                "doc": "ì„œìš¸ ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸ í‰ê·  ë§¤ë§¤ê°€ê²©ì´ ì „ì›” ëŒ€ë¹„ 2.3% ìƒìŠ¹í–ˆìŠµë‹ˆë‹¤. íŠ¹íˆ ëŒ€ì¹˜ë™ê³¼ ì‚¼ì„±ë™ ì¼ëŒ€ì˜ ëŒ€ë‹¨ì§€ ì•„íŒŒíŠ¸ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ê°€ê²© ìƒìŠ¹ì„¸ê°€ ëšœë ·í•˜ê²Œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.",
                "metadata": {"region": "ê°•ë‚¨êµ¬", "date": "2025-01", "price_trend": "ìƒìŠ¹", "article_type": "ì‹œì¥ë¶„ì„"}
            },
            {
                "doc": "ì†¡íŒŒêµ¬ ì ì‹¤ ì¼ëŒ€ ì „ì„¸ ê°€ê²©ì´ ì•ˆì •ì„¸ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤. ì‹ ê·œ ì•„íŒŒíŠ¸ ê³µê¸‰ê³¼ í•¨ê»˜ ì „ì„¸ ìˆ˜ìš”ê°€ ë¶„ì‚°ë˜ë©´ì„œ ê°€ê²© ìƒìŠ¹í­ì´ ë‘”í™”ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "metadata": {"region": "ì†¡íŒŒêµ¬", "date": "2025-01", "price_trend": "ì•ˆì •", "article_type": "ì‹œì¥ë¶„ì„"}
            },
            {
                "doc": "ì •ë¶€ì˜ ë¶€ë™ì‚° ê·œì œ ì™„í™” ì •ì±… ë°œí‘œ ì´í›„ ì„œìš¸ ì£¼ìš” ì§€ì—­ì˜ ê±°ë˜ëŸ‰ì´ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ ê°•ë‚¨ 3êµ¬ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë§¤ìˆ˜ ë¬¸ì˜ê°€ ëŠ˜ì–´ë‚˜ê³  ìˆìŠµë‹ˆë‹¤.",
                "metadata": {"region": "ì„œìš¸", "date": "2025-01", "price_trend": "ê±°ë˜ì¦ê°€", "article_type": "ì •ì±…ë¶„ì„"}
            }
        ]
        
        collection.add(
            documents=[item["doc"] for item in sample_docs],
            metadatas=[item["metadata"] for item in sample_docs],
            ids=[f"doc_{i}" for i in range(len(sample_docs))]
        )
        
        return collection
    except:
        # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš°
        return client.get_collection(name="real_estate_prices_20250511")

# ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸°
def get_collection(collection_name):
    try:
        client = init_chroma_client()
        
        # ì»¬ë ‰ì…˜ ëª©ë¡ í™•ì¸
        existing_collections = [col.name for col in client.list_collections()]
        
        if collection_name in existing_collections:
            collection = client.get_collection(name=collection_name)
        else:
            # ìƒ˜í”Œ ë°ì´í„°ë¡œ ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±
            st.sidebar.info(f"'{collection_name}' ì»¬ë ‰ì…˜ì´ ì—†ì–´ ìƒ˜í”Œ ë°ì´í„°ë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
            collection = load_sample_data(client)
        
        return collection
    except Exception as e:
        st.sidebar.error(f"ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {e}")
        return None

# ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ í•¨ìˆ˜
def search_vector_db(collection, query, n_results=20):
    try:
        if not collection:
            return [{"content": "ì»¬ë ‰ì…˜ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì»¬ë ‰ì…˜ ì´ë¦„ì„ í™•ì¸í•˜ì„¸ìš”.", "title": "ì˜¤ë¥˜", "metadata": {}}]
        
        results = collection.query(
            query_texts=[query],
            n_results=min(n_results, collection.count())
        )
        
        documents = []
        if results['documents'] and len(results['documents'][0]) > 0:
            for i in range(len(results['documents'][0])):
                document = {
                    "content": results['documents'][0][i],
                    "title": results['metadatas'][0][i].get('title', 'ì œëª© ì—†ìŒ'),
                    "metadata": results['metadatas'][0][i]
                }
                documents.append(document)
        
        return documents
    except Exception as e:
        st.sidebar.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return [{"content": f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", "title": "ì˜¤ë¥˜", "metadata": {}}]

# OpenAIë¥¼ í™œìš©í•œ ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def get_gpt_response(query, search_results, api_key, model="gpt-4o-mini"):
    if not api_key:
        return "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit Cloud Settingsì—ì„œ Secretsë¥¼ ì„¤ì •í•˜ê±°ë‚˜ ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."

    try:
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        api_key = api_key.strip().replace('\ufeff', '')
        client = OpenAI(api_key=api_key)
        
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = "ë‹¤ìŒì€ ë‰´ìŠ¤ ê¸°ì‚¬ì™€ ë³´ê³ ì„œì—ì„œ ìˆ˜ì§‘í•œ ë¶€ë™ì‚° ê°€ê²© ê´€ë ¨ ë°ì´í„°ì…ë‹ˆë‹¤:\n\n"
        
        for i, result in enumerate(search_results):
            context += f"ë¬¸ì„œ {i+1}:\n"
            context += f"ì œëª©: {result['title']}\n"
            
            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            if result['metadata']:
                metadata = result['metadata']
                if 'date' in metadata:
                    context += f"ì‘ì„±ì¼: {metadata['date']}\n"
                if 'region' in metadata:
                    context += f"ì§€ì—­: {metadata['region']}\n"
                if 'price_trend' in metadata:
                    context += f"ê°€ê²© ë™í–¥: {metadata['price_trend']}\n"
                if 'article_type' in metadata:
                    context += f"ê¸°ì‚¬ ìœ í˜•: {metadata['article_type']}\n"
            
            # ë‚´ìš© ìš”ì•½ (ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ëƒ„)
            content = result['content']
            if len(content) > 8000:
                content = content[:8000] + "..."
            context += f"ë‚´ìš©: {content}\n\n"
        
        # ê°œì„ ëœ GPT í”„ë¡¬í”„íŠ¸
        system_prompt = """ë‹¹ì‹ ì€ ë¶€ë™ì‚° ì‹œì¥ ë° ê°€ê²© ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ë¬¸ì„œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì—
        ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

        ë‹µë³€ ì‘ì„± ê°€ì´ë“œë¼ì¸:
        1. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ ë‚´ìš©ë§Œ ë‹µë³€í•˜ì„¸ìš”.
        2. ë¶€ë™ì‚° ê°€ê²© ë™í–¥, ì§€ì—­ë³„ ì‹œì„¸, ê°€ê²© ë³€ë™ ìš”ì¸ ë“±ì— ëŒ€í•´ ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.
        3. ì œê³µëœ ë¬¸ì„œì— í™•ì¸í•  ìˆ˜ ìˆëŠ” ì‚¬ì‹¤ì— ê¸°ë°˜í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
        4. ë‹µë³€ì€ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
        5. ë¶€ë™ì‚° íˆ¬ì ì¡°ì–¸ì´ë‚˜ ë²•ì  ì¡°ì–¸ì„ ì œê³µí•˜ì§€ ë§ˆì„¸ìš”.
        """

        user_prompt = f"""{context}

        ì‚¬ìš©ì ì§ˆë¬¸: {query}

        ìœ„ ë¬¸ì„œë“¤ì„ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ë§Œ ì§ì ‘ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
        ì§ˆë¬¸ì— ê´€ë ¨ëœ ì •ë³´ë§Œ ì œê³µí•˜ê³ , ë¶ˆí•„ìš”í•œ ë°°ê²½ì„¤ëª…ì´ë‚˜ ì¶”ê°€ ì •ë³´ëŠ” ìƒëµí•´ì£¼ì„¸ìš”.
        """
                
        # API í˜¸ì¶œ
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.5,
            max_tokens=800
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        error_msg = str(e)
        
        # ì¸ì¦ ì˜¤ë¥˜ í™•ì¸
        if "auth" in error_msg.lower() or "api key" in error_msg.lower():
            return "OpenAI API í‚¤ ì¸ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
        else:
            return f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg}"

# ë¶€ë™ì‚°ê³¼ ê´€ë ¨ì—†ëŠ” ì§ˆë¬¸ì„ í–ˆì„ë•Œ ê°„ë‹¨í•œ ì‘ë‹µì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
def get_simple_response(query, search_results):
    if not search_results or search_results[0].get("title") == "ì˜¤ë¥˜":
        return "ê´€ë ¨ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    result_text = f"'{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼:\n\n"
    
    for i, result in enumerate(search_results[:3]):  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
        result_text += f"**ë¬¸ì„œ {i+1}:** {result['title']}\n"
        
        # ë‚´ìš© ìš”ì•½ (100ìë¡œ ì œí•œ)
        content = result['content']
        if len(content) > 100:
            content = content[:100] + "..."
        result_text += f"{content}\n\n"
    
    result_text += "ë” ìì„¸í•œ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
    return result_text

# ì±—ë´‡ ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def chat_response(question, collection):
    # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰
    search_results = search_vector_db(collection, question)
    
    # ChatGPT API í‚¤ê°€ ìˆìœ¼ë©´ GPT ì‚¬ìš©, ì—†ìœ¼ë©´ ê°„ë‹¨í•œ ì‘ë‹µ
    if api_key:
        return get_gpt_response(question, search_results, api_key)
    else:
        return get_simple_response(question, search_results)

# ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸°
collection = get_collection(collection_name)

# ì»¬ë ‰ì…˜ ì •ë³´ í‘œì‹œ
if collection:
    try:
        count = collection.count()
        st.sidebar.success(f"âœ… ì»¬ë ‰ì…˜ '{collection_name}'ì—ì„œ {count}ê°œì˜ ë¬¸ì„œë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
    except Exception as e:
        st.sidebar.warning(f"ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
else:
    st.sidebar.warning(f"âš ï¸ ì»¬ë ‰ì…˜ '{collection_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# ì´ì „ ëŒ€í™” ë‚´ìš© í‘œì‹œ
for message in st.session_state.chat_history:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì„œìš¸ ê°•ë‚¨ ì•„íŒŒíŠ¸ ê°€ê²© ë™í–¥ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?)"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    with st.chat_message("user"):
        st.markdown(prompt)

    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™” ì´ë ¥ì— ì €ì¥
    st.session_state.chat_history.append({"role": "user", "content": prompt})

    # ì‘ë‹µ ìƒì„±
    with st.spinner("ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¶€ë™ì‚° ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ë‹µë³€ì„ ì¤€ë¹„í•˜ê³  ìˆëŠ” ì¤‘..."):
        response = chat_response(prompt, collection)

    # ì‘ë‹µ ë©”ì‹œì§€ í‘œì‹œ
    with st.chat_message("assistant"):
        st.markdown(response)

    # AI ì‘ë‹µì„ ëŒ€í™” ì´ë ¥ì— ì €ì¥
    st.session_state.chat_history.append({"role": "assistant", "content": response})

# ì‚¬ì´ë“œë°” ì˜ˆì‹œ ì§ˆë¬¸
st.sidebar.header("ì˜ˆì‹œ ì§ˆë¬¸")
example_questions = [
    "ì„œìš¸ ê°•ë‚¨ ì•„íŒŒíŠ¸ ê°€ê²© ë™í–¥ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
    "ìµœê·¼ ì „ì„¸ ì‹œì¥ì˜ ë³€í™” ì¶”ì´ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.",
    "ì–´ë–¤ ì •ì±…ì´ ë¶€ë™ì‚° ê°€ê²©ì— ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì³¤ë‚˜ìš”?",
    "ì§€ë°© ë¶€ë™ì‚° ì‹œì¥ì€ ì„œìš¸ê³¼ ë¹„êµí•˜ì—¬ ì–´ë–¤ ìƒí™©ì¸ê°€ìš”?",
    "ë¶€ë™ì‚° ê°€ê²© ìƒìŠ¹ì˜ ì£¼ìš” ì›ì¸ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    "ì†¡íŒŒêµ¬ì™€ ê°•ë‚¨êµ¬ì˜ ì•„íŒŒíŠ¸ ê°€ê²©ì„ ë¹„êµí•´ì£¼ì„¸ìš”."
]

# ì˜ˆì‹œ ì§ˆë¬¸ ë²„íŠ¼
for question in example_questions:
    if st.sidebar.button(question, key=f"ex_{question[:10]}"):
        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ ë° ì €ì¥
        with st.chat_message("user"):
            st.markdown(question)
        st.session_state.chat_history.append({"role": "user", "content": question})

        # ì‘ë‹µ ìƒì„±
        with st.spinner("ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¶€ë™ì‚° ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ë¶„ì„í•˜ê³  ìˆëŠ” ì¤‘..."):
            response = chat_response(question, collection)

        # ì‘ë‹µ ë©”ì‹œì§€ í‘œì‹œ ë° ì €ì¥
        with st.chat_message("assistant"):
            st.markdown(response)
        st.session_state.chat_history.append({"role": "assistant", "content": response})

        # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
        st.rerun()

# ë°ì´í„° ì‹œê°í™” ì„¹ì…˜ ì¶”ê°€
st.sidebar.header("ë°ì´í„° ì‹œê°í™”")
if st.sidebar.button("ê°€ê²© ë™í–¥ ì°¨íŠ¸ ë³´ê¸°"):
    st.session_state.show_chart = True

# ë°ì´í„° ë¶„ì„ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ëŠ” ì°¨íŠ¸ (ì˜ˆì‹œ)
if "show_chart" in st.session_state and st.session_state.show_chart:
    st.subheader("ì£¼ìš” ì§€ì—­ ë¶€ë™ì‚° ê°€ê²© ë™í–¥")
    st.line_chart({
        "ê°•ë‚¨": [100, 105, 110, 108, 115, 120],
        "ì†¡íŒŒ": [90, 95, 100, 103, 107, 110],
        "ë§ˆí¬": [80, 82, 85, 87, 90, 92]
    })
    st.caption("ìµœê·¼ 6ê°œì›” ë¶€ë™ì‚° ê°€ê²© ì§€ìˆ˜ (ê¸°ì¤€ì : 100)")

# ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” ë²„íŠ¼
if st.sidebar.button("ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"):
    st.session_state.chat_history = []
    st.rerun()

# ì»¬ë ‰ì…˜ ëª©ë¡ í‘œì‹œ
try:
    client = init_chroma_client()
    collections = client.list_collections()
    
    with st.sidebar.expander("ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ë ‰ì…˜ ëª©ë¡"):
        if collections:
            for coll in collections:
                st.write(f"- {coll.name}")
        else:
            st.write("ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ë ‰ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")
except Exception as e:
    st.sidebar.error(f"ì»¬ë ‰ì…˜ ëª©ë¡ ë¡œë“œ ì˜¤ë¥˜: {e}")
