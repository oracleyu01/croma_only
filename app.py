# AI News Analysis Agent - Stable Version
import streamlit as st
import json
from openai import OpenAI
import re
import urllib.request
import urllib.parse
from datetime import datetime
import time
from collections import Counter

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AI News Intelligence Hub", 
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ê°„ë‹¨í•œ ìŠ¤íƒ€ì¼ ì ìš©
st.markdown("""
<style>
    .main {
        padding-top: 2rem;
    }
    
    .stButton > button {
        width: 100%;
        background-color: #6366f1;
        color: white;
        border-radius: 8px;
        padding: 0.75rem;
        font-weight: 600;
    }
    
    .stButton > button:hover {
        background-color: #4f46e5;
    }
    
    .metric-container {
        background-color: #f3f4f6;
        padding: 1.5rem;
        border-radius: 12px;
        text-align: center;
        box-shadow: 0 1px 3px rgba(0,0,0,0.1);
    }
    
    .news-card {
        background-color: #ffffff;
        padding: 1.5rem;
        border-radius: 12px;
        border: 1px solid #e5e7eb;
        margin-bottom: 1rem;
        box-shadow: 0 1px 3px rgba(0,0,0,0.1);
    }
</style>
""", unsafe_allow_html=True)

# API í‚¤ ê°€ì ¸ì˜¤ê¸°
def get_api_keys():
    """Streamlit secretsì—ì„œ API í‚¤ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    openai_key = None
    naver_client_id = None
    naver_client_secret = None
    
    try:
        openai_key = st.secrets["OPENAI_API_KEY"]
    except:
        openai_key = st.sidebar.text_input("ğŸ”‘ OpenAI API í‚¤", type="password", help="OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
    
    try:
        naver_client_id = st.secrets["NAVER_CLIENT_ID"]
        naver_client_secret = st.secrets["NAVER_CLIENT_SECRET"]
    except:
        with st.sidebar.expander("ğŸ” ë„¤ì´ë²„ API ì„¤ì •"):
            naver_client_id = st.text_input("ë„¤ì´ë²„ Client ID", help="ë„¤ì´ë²„ ê°œë°œì ì„¼í„°ì—ì„œ ë°œê¸‰ë°›ì€ ID")
            naver_client_secret = st.text_input("ë„¤ì´ë²„ Client Secret", type="password", help="ë„¤ì´ë²„ ê°œë°œì ì„¼í„°ì—ì„œ ë°œê¸‰ë°›ì€ Secret")
    
    return openai_key, naver_client_id, naver_client_secret

# API í‚¤ ê°€ì ¸ì˜¤ê¸°
openai_key, naver_client_id, naver_client_secret = get_api_keys()

# ì„¸ì…˜ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if "articles" not in st.session_state:
    st.session_state.articles = []
if "search_keyword" not in st.session_state:
    st.session_state.search_keyword = ""

# ì¹´í…Œê³ ë¦¬ ì •ì˜
CATEGORIES = {
    "ğŸ’¹ ê²½ì œ": ["ê²½ì œ", "ê¸ˆë¦¬", "í™˜ìœ¨", "ì£¼ì‹", "ë¶€ë™ì‚°", "ë¬¼ê°€", "ì‹¤ì—…", "íˆ¬ì"],
    "ğŸ›ï¸ ì •ì¹˜": ["ì •ì¹˜", "êµ­íšŒ", "ëŒ€í†µë ¹", "ì„ ê±°", "ì •ë‹¹", "ì™¸êµ", "ì •ì±…"],
    "ğŸ’» IT/ê³¼í•™": ["AI", "ì¸ê³µì§€ëŠ¥", "ë°˜ë„ì²´", "ì „ê¸°ì°¨", "ë°”ì´ì˜¤", "ìš°ì£¼", "IT", "ê¸°ìˆ "],
    "ğŸ­ ë¬¸í™”": ["ë¬¸í™”", "KíŒ", "ë“œë¼ë§ˆ", "ì˜í™”", "ìŠ¤í¬ì¸ ", "ê²Œì„", "ê´€ê´‘"],
    "ğŸ‘¥ ì‚¬íšŒ": ["ì‚¬íšŒ", "êµìœ¡", "ì˜ë£Œ", "ë³µì§€", "ë²”ì£„", "í™˜ê²½", "ë…¸ë™"],
    "ğŸŒ êµ­ì œ": ["êµ­ì œ", "ë¯¸êµ­", "ì¤‘êµ­", "ì¼ë³¸", "ëŸ¬ì‹œì•„", "ìœ ëŸ½", "UN"]
}

# ë‰´ìŠ¤ ê²€ìƒ‰ í•¨ìˆ˜
@st.cache_data(ttl=1800)
def search_naver_news(query, display=20, start=1, sort="date"):
    """ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    if not naver_client_id or not naver_client_secret:
        return []
    
    try:
        encText = urllib.parse.quote(query)
        url = f"https://openapi.naver.com/v1/search/news.json?query={encText}&display={display}&start={start}&sort={sort}"
        
        request = urllib.request.Request(url)
        request.add_header("X-Naver-Client-Id", naver_client_id)
        request.add_header("X-Naver-Client-Secret", naver_client_secret)
        
        response = urllib.request.urlopen(request)
        rescode = response.getcode()
        
        if rescode == 200:
            response_body = response.read()
            result = json.loads(response_body.decode('utf-8'))
            
            articles = []
            for item in result.get('items', []):
                title = re.sub('<[^<]+?>', '', item['title'])
                description = re.sub('<[^<]+?>', '', item['description'])
                
                pub_date = datetime.strptime(item['pubDate'], '%a, %d %b %Y %H:%M:%S +0900')
                
                # ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
                category = categorize_article(title, description)
                
                articles.append({
                    "title": title,
                    "content": description,
                    "date": pub_date.strftime("%Y-%m-%d"),
                    "time": pub_date.strftime("%H:%M"),
                    "category": category,
                    "url": item['link'],
                    "source": item.get('originallink', item['link'])
                })
            
            return articles
        else:
            return []
            
    except Exception as e:
        st.error(f"âŒ ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

def categorize_article(title, content):
    """ê¸°ì‚¬ ì¹´í…Œê³ ë¦¬ ìë™ ë¶„ë¥˜"""
    text = (title + " " + content).lower()
    
    scores = {}
    for cat, keywords in CATEGORIES.items():
        score = sum(1 for kw in keywords if kw in text)
        if score > 0:
            scores[cat] = score
    
    return max(scores, key=scores.get) if scores else "ğŸ“° ì¼ë°˜"

def get_gpt_response(query, articles):
    """GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ ë¶„ì„"""
    if not openai_key:
        return simple_response(query, articles)
    
    try:
        client = OpenAI(api_key=openai_key.strip())
        
        context = "ê´€ë ¨ ë‰´ìŠ¤ ê¸°ì‚¬:\n\n"
        for i, article in enumerate(articles[:5]):
            context += f"[ê¸°ì‚¬ {i+1}]\n"
            context += f"ì œëª©: {article['title']}\n"
            context += f"ë‚ ì§œ: {article['date']} {article.get('time', '')}\n"
            context += f"ë‚´ìš©: {article['content']}\n"
            context += f"ì¶œì²˜: {article['source']}\n\n"
        
        system_prompt = """ë‹¹ì‹ ì€ ë‰´ìŠ¤ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì œê³µëœ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ë¶„ì„í•˜ì—¬ ëª…í™•í•˜ê³  í†µì°°ë ¥ ìˆëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
ë‹µë³€ì—ëŠ” ë‹¤ìŒì„ í¬í•¨í•˜ì„¸ìš”:
1. í•µì‹¬ ìš”ì•½
2. ì£¼ìš” íŠ¸ë Œë“œë‚˜ íŒ¨í„´
3. ì‹¤ìš©ì ì¸ ì¸ì‚¬ì´íŠ¸
ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì—¬ ì½ê¸° ì‰½ê²Œ ë§Œë“œì„¸ìš”."""
        
        user_prompt = f"{context}\nì‚¬ìš©ì ì§ˆë¬¸: {query}\n\nìœ„ ê¸°ì‚¬ë“¤ì„ ë¶„ì„í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”."
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7,
            max_tokens=800
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        return simple_response(query, articles)

def simple_response(query, articles):
    """GPT ì—†ì´ ê°„ë‹¨í•œ ì‘ë‹µ ìƒì„±"""
    if not articles:
        return "ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ğŸ˜”"
    
    response = f"ğŸ“° **'{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼:**\n\n"
    for i, article in enumerate(articles[:3]):
        response += f"### {i+1}. {article['title']}\n"
        response += f"ğŸ“… {article['date']} {article.get('time', '')} | ğŸ·ï¸ {article.get('category', 'ì¼ë°˜')}\n\n"
        response += f"{article['content'][:200]}...\n\n"
        response += f"ğŸ”— [ê¸°ì‚¬ ì „ë¬¸ ë³´ê¸°]({article['url']})\n\n"
        response += "---\n\n"
    
    return response

# í—¤ë”
st.markdown("# ğŸš€ AI News Intelligence Hub")
st.markdown("ì‹¤ì‹œê°„ ë‰´ìŠ¤ ìˆ˜ì§‘ â€¢ AI ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„ â€¢ ë°ì´í„° ì‹œê°í™”")
st.markdown("---")

# ì‚¬ì´ë“œë°”
st.sidebar.markdown("## âš™ï¸ Control Center")

# API ìƒíƒœ í‘œì‹œ
api_status = []
if openai_key and openai_key.startswith("sk-"):
    api_status.append("âœ… OpenAI")
else:
    api_status.append("âŒ OpenAI")

if naver_client_id and naver_client_secret:
    api_status.append("âœ… Naver")
else:
    api_status.append("âŒ Naver")

st.sidebar.info(f"API ì—°ê²° ìƒíƒœ: {' | '.join(api_status)}")

# ë¶„ì„ ëª¨ë“œ
st.sidebar.markdown("### ğŸ¯ ë¶„ì„ ëª¨ë“œ")
analysis_mode = st.sidebar.radio(
    "ëª¨ë“œ ì„ íƒ",
    ["ëŒ€í™”í˜• ë¶„ì„", "ë°ì´í„° ì‹œê°í™”", "ì‹¬ì¸µ ë¶„ì„"]
)

# ë‰´ìŠ¤ ìˆ˜ì§‘
st.sidebar.markdown("### ğŸ” ë‰´ìŠ¤ ìˆ˜ì§‘")
search_keyword = st.sidebar.text_input(
    "ê²€ìƒ‰ì–´ ì…ë ¥", 
    placeholder="ì˜ˆ: AI, ê²½ì œ, ì„ ê±°..."
)

col1, col2 = st.sidebar.columns(2)
with col1:
    num_articles = st.selectbox("ê¸°ì‚¬ ìˆ˜", [20, 30, 50, 100])
with col2:
    sort_option = st.selectbox("ì •ë ¬", ["date", "sim"], 
                             format_func=lambda x: "ìµœì‹ ìˆœ" if x == "date" else "ì •í™•ë„ìˆœ")

if st.sidebar.button("ğŸš€ ë‰´ìŠ¤ ìˆ˜ì§‘", type="primary"):
    if search_keyword:
        with st.spinner("ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            articles = search_naver_news(search_keyword, display=num_articles, sort=sort_option)
            if articles:
                st.session_state.articles = articles
                st.session_state.search_keyword = search_keyword
                st.success(f"âœ… {len(articles)}ê°œ ê¸°ì‚¬ ìˆ˜ì§‘ ì™„ë£Œ!")
                st.balloons()
            else:
                st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.error("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")

# ì´ˆê¸°í™” ë²„íŠ¼
if st.sidebar.button("ğŸ—‘ï¸ ì´ˆê¸°í™”"):
    st.session_state.messages = []
    st.session_state.articles = []
    st.rerun()

# ì‹¤ì‹œê°„ íŠ¸ë Œë“œ
st.sidebar.markdown("### ğŸ”¥ ì‹¤ì‹œê°„ íŠ¸ë Œë“œ")
trending_keywords = ["ì‚¼ì„±ì „ì", "í…ŒìŠ¬ë¼", "AI", "ë¶€ë™ì‚°", "ê¸ˆë¦¬", "ìš°í¬ë¼ì´ë‚˜", "KíŒ"]
for keyword in trending_keywords:
    if st.sidebar.button(f"ğŸ” {keyword}", key=f"trend_{keyword}"):
        with st.spinner(f"'{keyword}' ê²€ìƒ‰ ì¤‘..."):
            articles = search_naver_news(keyword, display=20)
            if articles:
                st.session_state.articles = articles
                st.session_state.search_keyword = keyword
                st.rerun()

# ë©”ì¸ ì»¨í…ì¸ 
if not st.session_state.articles:
    # í™˜ì˜ í™”ë©´
    st.markdown("""
    ## ğŸ¯ ë‰´ìŠ¤ ì¸í…”ë¦¬ì „ìŠ¤ ì‹œì‘í•˜ê¸°
    
    AIê°€ ì‹¤ì‹œê°„ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ì—¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    
    ### ğŸ“š ì‚¬ìš© ë°©ë²•
    1. ì‚¬ì´ë“œë°”ì—ì„œ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ê±°ë‚˜
    2. ì‹¤ì‹œê°„ íŠ¸ë Œë“œì—ì„œ í‚¤ì›Œë“œë¥¼ ì„ íƒí•˜ì—¬
    3. ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•œ í›„ ì§ˆë¬¸í•´ë³´ì„¸ìš”!
    
    ### ğŸ’¡ ì£¼ìš” ê¸°ëŠ¥
    - ğŸ” **ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰**: í‚¤ì›Œë“œ ê¸°ë°˜ ì •ë°€ ê²€ìƒ‰
    - ğŸ¤– **AI ë¶„ì„**: GPT ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„
    - ğŸ“Š **ë°ì´í„° ì‹œê°í™”**: í†µê³„ ë° íŠ¸ë Œë“œ ë¶„ì„
    """)
else:
    # í†µê³„ í‘œì‹œ
    if st.session_state.articles:
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ğŸ” ê²€ìƒ‰ì–´", st.session_state.search_keyword)
        
        with col2:
            st.metric("ğŸ“° ê¸°ì‚¬ ìˆ˜", f"{len(st.session_state.articles)}ê°œ")
        
        with col3:
            latest_date = max(art['date'] for art in st.session_state.articles)
            st.metric("ğŸ“… ìµœì‹  ê¸°ì‚¬", latest_date)
        
        with col4:
            categories = [art.get('category', 'ì¼ë°˜') for art in st.session_state.articles]
            most_common = max(set(categories), key=categories.count)
            st.metric("ğŸ·ï¸ ì£¼ìš” ì¹´í…Œê³ ë¦¬", most_common)
    
    st.markdown("---")
    
    if analysis_mode == "ëŒ€í™”í˜• ë¶„ì„":
        # ëŒ€í™”í˜• ë¶„ì„ ëª¨ë“œ
        st.markdown("## ğŸ’¬ ëŒ€í™”í˜• ë¶„ì„")
        
        # ì˜ˆì‹œ ì§ˆë¬¸ ë²„íŠ¼ë“¤
        st.markdown("### ğŸ’¡ ë¹ ë¥¸ ì§ˆë¬¸í•˜ê¸°")
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ“ˆ ì´ ì£¼ì œì˜ ìµœì‹  ë™í–¥ì€?", use_container_width=True):
                question = "ì´ ì£¼ì œì— ëŒ€í•œ ìµœì‹  ë™í–¥ì€ ë¬´ì—‡ì¸ê°€ìš”?"
                st.session_state.messages.append({"role": "user", "content": question})
                with st.spinner("AIê°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                    response = get_gpt_response(question, st.session_state.articles)
                st.session_state.messages.append({"role": "assistant", "content": response})
                st.rerun()
                
            if st.button("ğŸ’­ ì „ë¬¸ê°€ë“¤ì˜ ì˜ê²¬ì€?", use_container_width=True):
                question = "ì´ ì£¼ì œì— ëŒ€í•œ ì „ë¬¸ê°€ë“¤ì˜ ì˜ê²¬ì€ ì–´ë–¤ê°€ìš”?"
                st.session_state.messages.append({"role": "user", "content": question})
                with st.spinner("AIê°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                    response = get_gpt_response(question, st.session_state.articles)
                st.session_state.messages.append({"role": "assistant", "content": response})
                st.rerun()
        
        with col2:
            if st.button("ğŸ”® í–¥í›„ ì „ë§ì€?", use_container_width=True):
                question = "ì´ ì£¼ì œì˜ í–¥í›„ ì „ë§ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"
                st.session_state.messages.append({"role": "user", "content": question})
                with st.spinner("AIê°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                    response = get_gpt_response(question, st.session_state.articles)
                st.session_state.messages.append({"role": "assistant", "content": response})
                st.rerun()
                
            if st.button("âš¡ ì£¼ìš” ì´ìŠˆëŠ”?", use_container_width=True):
                question = "í˜„ì¬ ê°€ì¥ ì¤‘ìš”í•œ ì´ìŠˆëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
                st.session_state.messages.append({"role": "user", "content": question})
                with st.spinner("AIê°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                    response = get_gpt_response(question, st.session_state.articles)
                st.session_state.messages.append({"role": "assistant", "content": response})
                st.rerun()
        
        st.markdown("---")
        
        # ëŒ€í™” í‘œì‹œ
        if st.session_state.messages:
            for msg in st.session_state.messages:
                with st.chat_message(msg["role"]):
                    st.markdown(msg["content"])
                    
                    # assistant ë©”ì‹œì§€ì¼ ë•Œ ê´€ë ¨ ê¸°ì‚¬ í‘œì‹œ
                    if msg["role"] == "assistant" and st.session_state.articles:
                        with st.expander("ğŸ“ ì°¸ê³  ê¸°ì‚¬", expanded=False):
                            for i, art in enumerate(st.session_state.articles[:3]):
                                st.markdown(f"**{i+1}. [{art['title']}]({art['url']})**")
                                st.caption(f"{art['date']} | {art.get('category', 'ì¼ë°˜')}")
                                st.write(art['content'][:150] + "...")
                                if i < 2:
                                    st.markdown("---")
        
        # ì‚¬ìš©ì ì…ë ¥
        if prompt := st.chat_input("ë‰´ìŠ¤ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”"):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            
            with st.chat_message("assistant"):
                with st.spinner("AIê°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                    response = get_gpt_response(prompt, st.session_state.articles)
                st.markdown(response)
                
                # ê´€ë ¨ ê¸°ì‚¬ í‘œì‹œ
                with st.expander("ğŸ“ ì°¸ê³  ê¸°ì‚¬", expanded=False):
                    for i, art in enumerate(st.session_state.articles[:3]):
                        st.markdown(f"**{i+1}. [{art['title']}]({art['url']})**")
                        st.caption(f"{art['date']} | {art.get('category', 'ì¼ë°˜')}")
                        st.write(art['content'][:150] + "...")
                        if i < 2:
                            st.markdown("---")
            
            st.session_state.messages.append({"role": "assistant", "content": response})
    
    elif analysis_mode == "ë°ì´í„° ì‹œê°í™”":
        # ë°ì´í„° ì‹œê°í™” ëª¨ë“œ
        st.markdown("## ğŸ“Š ë°ì´í„° ì‹œê°í™”")
        
        # ì¹´í…Œê³ ë¦¬ ë¶„í¬
        categories = [art.get('category', 'ì¼ë°˜') for art in st.session_state.articles]
        cat_counts = Counter(categories)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### ğŸ“ˆ ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬")
            chart_data = {
                "ì¹´í…Œê³ ë¦¬": list(cat_counts.keys()),
                "ê¸°ì‚¬ ìˆ˜": list(cat_counts.values())
            }
            st.bar_chart(data=chart_data, x="ì¹´í…Œê³ ë¦¬", y="ê¸°ì‚¬ ìˆ˜", height=400)
        
        with col2:
            st.markdown("### ğŸ“… ë‚ ì§œë³„ ë¶„í¬")
            dates = [art['date'] for art in st.session_state.articles]
            date_counts = Counter(dates)
            
            date_data = {
                "ë‚ ì§œ": sorted(date_counts.keys()),
                "ê¸°ì‚¬ ìˆ˜": [date_counts[d] for d in sorted(date_counts.keys())]
            }
            st.line_chart(data=date_data, x="ë‚ ì§œ", y="ê¸°ì‚¬ ìˆ˜", height=400)
        
        # ì£¼ìš” í‚¤ì›Œë“œ
        st.markdown("### â˜ï¸ ì£¼ìš” í‚¤ì›Œë“œ")
        all_text = " ".join([art['title'] + " " + art['content'] for art in st.session_state.articles])
        words = all_text.split()
        
        # ë¶ˆìš©ì–´ ì œê±°
        stopwords = ['ì˜', 'ê°€', 'ì´', 'ì€', 'ë“¤', 'ëŠ”', 'ì¢€', 'ì˜', 'ê³¼', 'ë¥¼', 'ìœ¼ë¡œ', 'ì', 'ì—', 'í•œ', 'í•˜ë‹¤']
        words = [w for w in words if len(w) > 1 and w not in stopwords]
        
        word_freq = Counter(words)
        top_words = word_freq.most_common(20)
        
        # ì›Œë“œ í´ë¼ìš°ë“œ ìŠ¤íƒ€ì¼ë¡œ í‘œì‹œ
        word_html = ""
        for word, freq in top_words:
            size = min(2.5, 0.8 + (freq / top_words[0][1]) * 1.7)
            word_html += f'<span style="font-size: {size}rem; margin: 0.5rem; display: inline-block; color: #6366f1;">{word}</span>'
        
        st.markdown(word_html, unsafe_allow_html=True)
    
    else:
        # ì‹¬ì¸µ ë¶„ì„ ëª¨ë“œ
        st.markdown("## ğŸ” ì‹¬ì¸µ ë¶„ì„")
        
        analysis_type = st.selectbox(
            "ë¶„ì„ ìœ í˜• ì„ íƒ",
            ["ì¢…í•© ë¶„ì„", "íŠ¸ë Œë“œ ë¶„ì„", "ê°ì • ë¶„ì„", "ì˜ˆì¸¡ ë¶„ì„"]
        )
        
        if st.button("ğŸš€ ë¶„ì„ ì‹¤í–‰", type="primary"):
            with st.spinner("ì‹¬ì¸µ ë¶„ì„ì„ ì§„í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                analysis = get_gpt_response(
                    f"{analysis_type}: {st.session_state.search_keyword}",
                    st.session_state.articles
                )
                st.markdown(analysis)
        
        # ê¸°ì‚¬ ëª©ë¡
        st.markdown("### ğŸ“° ì „ì²´ ê¸°ì‚¬ ëª©ë¡")
        for i, art in enumerate(st.session_state.articles):
            with st.expander(f"{i+1}. {art['title']}", expanded=False):
                st.caption(f"ğŸ“… {art['date']} {art.get('time', '')} | ğŸ·ï¸ {art.get('category', 'ì¼ë°˜')}")
                st.write(art['content'])
                st.markdown(f"ğŸ”— [ê¸°ì‚¬ ì›ë¬¸]({art['url']})")

# í‘¸í„°
st.markdown("---")
st.markdown("Made with â¤ï¸ by AI News Intelligence Hub | Powered by OpenAI & Naver API")
