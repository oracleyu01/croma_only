# ëŒ€í™”í˜• ì³‡ë´‡ ì• í”Œë¦¬ì¼€ì´ì…˜ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import streamlit as st
import json
from openai import OpenAI
import re

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë¶€ë™ì‚° ê°€ê²© ë¶„ì„ AI ì—ì´ì „íŠ¸", page_icon="ğŸ ")

# OpenAI API í‚¤ ê°€ì ¸ì˜¤ê¸°
def get_api_key():
    """Streamlit secrets ë˜ëŠ” ì‚¬ì´ë“œë°” ì…ë ¥ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°"""
    try:
        return st.secrets["OPENAI_API_KEY"]
    except:
        return st.sidebar.text_input(
            "OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”", 
            type="password",
            help="Streamlit Cloudì—ì„œëŠ” Settings > Secretsì—ì„œ OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”"
        )

# ì‚¬ì´ë“œë°” ì„¤ì •
st.sidebar.title("ì„¤ì •")
api_key = get_api_key()

# API í‚¤ ìƒíƒœ í‘œì‹œ
if api_key and api_key.startswith("sk-"):
    st.sidebar.success("âœ… API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤")
else:
    st.sidebar.warning("âš ï¸ API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”")
    with st.sidebar.expander("API í‚¤ ì„¤ì • ë°©ë²•"):
        st.write("""
        **Streamlit Cloud:**
        1. App settings â†’ Secrets í´ë¦­
        2. ë‹¤ìŒ ë‚´ìš© ì¶”ê°€:
        ```
        OPENAI_API_KEY = "sk-..."
        ```
        
        **ë¡œì»¬ í™˜ê²½:**
        1. `.streamlit/secrets.toml` íŒŒì¼ ìƒì„±
        2. ìœ„ì™€ ê°™ì€ ë‚´ìš© ì¶”ê°€
        """)

# í˜ì´ì§€ ì œëª©
st.title("ğŸ  ë¶€ë™ì‚° ê°€ê²© ë¶„ì„ AI ë°ì´í„° ë¶„ì„ê°€")
st.write("ë‰´ìŠ¤ ê¸°ì‚¬ ë° ë³´ê³ ì„œì—ì„œ ìˆ˜ì§‘í•œ ë¶€ë™ì‚° ê°€ê²© ë°ì´í„°ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”.")

# ì´ë¯¸ì§€ í‘œì‹œ (ì˜µì…˜)
try:
    st.image("realestate.png", use_container_width=True)
except:
    pass

# ìƒ˜í”Œ ë°ì´í„° ì •ì˜
SAMPLE_DATA = [
    {
        "content": "ì„œìš¸ ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸ í‰ê·  ë§¤ë§¤ê°€ê²©ì´ ì „ì›” ëŒ€ë¹„ 2.3% ìƒìŠ¹í–ˆìŠµë‹ˆë‹¤. íŠ¹íˆ ëŒ€ì¹˜ë™ê³¼ ì‚¼ì„±ë™ ì¼ëŒ€ì˜ ëŒ€ë‹¨ì§€ ì•„íŒŒíŠ¸ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ê°€ê²© ìƒìŠ¹ì„¸ê°€ ëšœë ·í•˜ê²Œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. ì „ë¬¸ê°€ë“¤ì€ ì´ëŸ¬í•œ ìƒìŠ¹ì„¸ê°€ ë‹¹ë¶„ê°„ ì§€ì†ë  ê²ƒìœ¼ë¡œ ì „ë§í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
        "title": "ê°•ë‚¨êµ¬ ë¶€ë™ì‚° ì‹œì¥ ë™í–¥",
        "metadata": {"region": "ê°•ë‚¨êµ¬", "date": "2025-01", "price_trend": "ìƒìŠ¹", "article_type": "ì‹œì¥ë¶„ì„"}
    },
    {
        "content": "ì†¡íŒŒêµ¬ ì ì‹¤ ì¼ëŒ€ ì „ì„¸ ê°€ê²©ì´ ì•ˆì •ì„¸ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤. ì‹ ê·œ ì•„íŒŒíŠ¸ ê³µê¸‰ê³¼ í•¨ê»˜ ì „ì„¸ ìˆ˜ìš”ê°€ ë¶„ì‚°ë˜ë©´ì„œ ê°€ê²© ìƒìŠ¹í­ì´ ë‘”í™”ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹¤ ë¡¯ë°ì›”ë“œíƒ€ì›Œ ì¸ê·¼ ì•„íŒŒíŠ¸ì˜ ê²½ìš° ì „ì„¸ê°€ìœ¨ì´ 60% ìˆ˜ì¤€ì„ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
        "title": "ì†¡íŒŒêµ¬ ì „ì„¸ ì‹œì¥ ë¶„ì„",
        "metadata": {"region": "ì†¡íŒŒêµ¬", "date": "2025-01", "price_trend": "ì•ˆì •", "article_type": "ì‹œì¥ë¶„ì„"}
    },
    {
        "content": "ì •ë¶€ì˜ ë¶€ë™ì‚° ê·œì œ ì™„í™” ì •ì±… ë°œí‘œ ì´í›„ ì„œìš¸ ì£¼ìš” ì§€ì—­ì˜ ê±°ë˜ëŸ‰ì´ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ ê°•ë‚¨ 3êµ¬ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë§¤ìˆ˜ ë¬¸ì˜ê°€ ëŠ˜ì–´ë‚˜ê³  ìˆìŠµë‹ˆë‹¤. ëŒ€ì¶œ ê·œì œ ì™„í™”ì™€ ì–‘ë„ì„¸ ë¶€ë‹´ ê²½ê°ì´ ì£¼ìš” ìš”ì¸ìœ¼ë¡œ ë¶„ì„ë©ë‹ˆë‹¤.",
        "title": "ë¶€ë™ì‚° ì •ì±… ì˜í–¥ ë¶„ì„",
        "metadata": {"region": "ì„œìš¸", "date": "2025-01", "price_trend": "ê±°ë˜ì¦ê°€", "article_type": "ì •ì±…ë¶„ì„"}
    },
    {
        "content": "ë§ˆí¬êµ¬ ê³µë•ë™ ì¼ëŒ€ ì‹ ì¶• ì˜¤í”¼ìŠ¤í…” ë¶„ì–‘ê°€ê°€ í‰ë‹¹ 3,000ë§Œì›ì„ ëŒíŒŒí–ˆìŠµë‹ˆë‹¤. êµí†µ í˜¸ì¬ì™€ ê°œë°œ ê¸°ëŒ€ê°ìœ¼ë¡œ íˆ¬ì ìˆ˜ìš”ê°€ ëª°ë¦¬ê³  ìˆìŠµë‹ˆë‹¤. ê³µë•ì—­ íŠ¸ë¦¬í”Œì—­ì„¸ê¶Œì˜ ì…ì§€ì  ì¥ì ì´ ê°€ê²© ìƒìŠ¹ì„ ê²¬ì¸í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
        "title": "ë§ˆí¬êµ¬ ì˜¤í”¼ìŠ¤í…” ì‹œì¥",
        "metadata": {"region": "ë§ˆí¬êµ¬", "date": "2025-01", "price_trend": "ìƒìŠ¹", "article_type": "ë¶„ì–‘ì •ë³´"}
    },
    {
        "content": "ê²½ê¸°ë„ ì„±ë‚¨ì‹œ ë¶„ë‹¹êµ¬ ì£¼íƒ ì‹œì¥ì´ í™œê¸°ë¥¼ ë ê³  ìˆìŠµë‹ˆë‹¤. GTX ê°œí†µ ê¸°ëŒ€ê°ê³¼ í•¨ê»˜ ì „ì„¸ê°€ìœ¨ì´ í•˜ë½í•˜ë©´ì„œ ë§¤ë§¤ ì „í™˜ ìˆ˜ìš”ê°€ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤. íŒêµ í…Œí¬ë…¸ë°¸ë¦¬ ì¸ê·¼ ì•„íŒŒíŠ¸ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ê±°ë˜ê°€ í™œë°œí•©ë‹ˆë‹¤.",
        "title": "ë¶„ë‹¹ ë¶€ë™ì‚° ì‹œì¥ ë™í–¥",
        "metadata": {"region": "ë¶„ë‹¹êµ¬", "date": "2025-01", "price_trend": "í™œì„±í™”", "article_type": "ì‹œì¥ë¶„ì„"}
    }
]

# ê°„ë‹¨í•œ ê²€ìƒ‰ í•¨ìˆ˜
def search_data(query, data=SAMPLE_DATA):
    """í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰"""
    query_lower = query.lower()
    results = []
    
    # ê° ë¬¸ì„œì— ëŒ€í•´ ì ìˆ˜ ê³„ì‚°
    for item in data:
        score = 0
        content_lower = item["content"].lower()
        title_lower = item["title"].lower()
        
        # ì¿¼ë¦¬ë¥¼ ë‹¨ì–´ë¡œ ë¶„ë¦¬
        keywords = query_lower.split()
        
        for keyword in keywords:
            # ì œëª©ì— í¬í•¨ë˜ë©´ ë†’ì€ ì ìˆ˜
            if keyword in title_lower:
                score += 3
            # ë‚´ìš©ì— í¬í•¨ë˜ë©´ ì¤‘ê°„ ì ìˆ˜
            if keyword in content_lower:
                score += 2
            # ë©”íƒ€ë°ì´í„°ì— í¬í•¨ë˜ë©´ ë‚®ì€ ì ìˆ˜
            metadata_str = str(item["metadata"]).lower()
            if keyword in metadata_str:
                score += 1
            
            # ì§€ì—­ëª… íŠ¹ë³„ ì²˜ë¦¬
            if "region" in item["metadata"] and keyword in item["metadata"]["region"].lower():
                score += 5
        
        if score > 0:
            results.append((score, item))
    
    # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
    results.sort(key=lambda x: x[0], reverse=True)
    
    # ìƒìœ„ 3ê°œë§Œ ë°˜í™˜
    return [r[1] for r in results[:3]] if results else SAMPLE_DATA[:3]

# OpenAIë¥¼ í™œìš©í•œ ì‘ë‹µ ìƒì„±
def get_gpt_response(query, search_results, api_key):
    if not api_key:
        return "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

    try:
        client = OpenAI(api_key=api_key.strip())
        
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = "ë‹¤ìŒì€ ë¶€ë™ì‚° ê°€ê²© ê´€ë ¨ ë°ì´í„°ì…ë‹ˆë‹¤:\n\n"
        
        for i, result in enumerate(search_results):
            context += f"[ë¬¸ì„œ {i+1}]\n"
            context += f"ì œëª©: {result.get('title', 'ì œëª© ì—†ìŒ')}\n"
            
            if result.get('metadata'):
                metadata = result['metadata']
                context += f"ì§€ì—­: {metadata.get('region', 'N/A')}\n"
                context += f"ë‚ ì§œ: {metadata.get('date', 'N/A')}\n"
                context += f"ê°€ê²©ë™í–¥: {metadata.get('price_trend', 'N/A')}\n"
                context += f"ìœ í˜•: {metadata.get('article_type', 'N/A')}\n"
            
            context += f"ë‚´ìš©: {result['content']}\n\n"
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_prompt = """ë‹¹ì‹ ì€ ë¶€ë™ì‚° ì‹œì¥ ë° ê°€ê²© ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
        ì œê³µëœ ë¬¸ì„œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ì •í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
        ìˆ«ìë‚˜ í†µê³„ê°€ ìˆë‹¤ë©´ ë°˜ë“œì‹œ í¬í•¨ì‹œí‚¤ê³ , ì§€ì—­ë³„ íŠ¹ì„±ì„ ê³ ë ¤í•˜ì—¬ ì„¤ëª…í•˜ì„¸ìš”."""
        
        # API í˜¸ì¶œ
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"{context}\nì§ˆë¬¸: {query}"}
            ],
            temperature=0.7,
            max_tokens=800
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        error_msg = str(e)
        if "api key" in error_msg.lower():
            return "OpenAI API í‚¤ ì¸ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
        else:
            return f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg}"

# ê°„ë‹¨í•œ ì‘ë‹µ ìƒì„±
def get_simple_response(query, search_results):
    if not search_results:
        return "ê´€ë ¨ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    result_text = f"ğŸ’¡ '{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤:\n\n"
    
    for i, result in enumerate(search_results):
        result_text += f"### {i+1}. {result.get('title', f'ë¬¸ì„œ {i+1}')}\n"
        
        # ë©”íƒ€ë°ì´í„° í‘œì‹œ
        if result.get('metadata'):
            meta = result['metadata']
            result_text += f"ğŸ“ ì§€ì—­: {meta.get('region', 'N/A')} | "
            result_text += f"ğŸ“… ì‹œê¸°: {meta.get('date', 'N/A')} | "
            result_text += f"ğŸ“Š ë™í–¥: {meta.get('price_trend', 'N/A')}\n\n"
        
        # ë‚´ìš© ìš”ì•½
        content = result['content']
        if len(content) > 200:
            content = content[:200] + "..."
        result_text += f"{content}\n\n"
        result_text += "---\n\n"
    
    result_text += "\nğŸ’¡ ë” ìì„¸í•œ ë¶„ì„ì„ ì›í•˜ì‹œë©´ OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
    return result_text

# ì±—ë´‡ ì‘ë‹µ ìƒì„±
def chat_response(question):
    # ë°ì´í„° ê²€ìƒ‰
    search_results = search_data(question)
    
    # API í‚¤ê°€ ìˆìœ¼ë©´ GPT ì‚¬ìš©, ì—†ìœ¼ë©´ ê°„ë‹¨í•œ ì‘ë‹µ
    if api_key and api_key.startswith("sk-"):
        return get_gpt_response(question, search_results, api_key)
    else:
        return get_simple_response(question, search_results)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# ì´ì „ ëŒ€í™” ë‚´ìš© í‘œì‹œ
for message in st.session_state.chat_history:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì„œìš¸ ê°•ë‚¨ ì•„íŒŒíŠ¸ ê°€ê²© ë™í–¥ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?)"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # ëŒ€í™” ì´ë ¥ì— ì €ì¥
    st.session_state.chat_history.append({"role": "user", "content": prompt})
    
    # ì‘ë‹µ ìƒì„±
    with st.spinner("ë‹µë³€ì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        response = chat_response(prompt)
    
    # ì‘ë‹µ í‘œì‹œ
    with st.chat_message("assistant"):
        st.markdown(response)
    
    # ëŒ€í™” ì´ë ¥ì— ì €ì¥
    st.session_state.chat_history.append({"role": "assistant", "content": response})

# ì‚¬ì´ë“œë°” ì˜ˆì‹œ ì§ˆë¬¸
st.sidebar.header("ì˜ˆì‹œ ì§ˆë¬¸")
example_questions = [
    "ì„œìš¸ ê°•ë‚¨ ì•„íŒŒíŠ¸ ê°€ê²© ë™í–¥ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
    "ìµœê·¼ ì „ì„¸ ì‹œì¥ì˜ ë³€í™” ì¶”ì´ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.",
    "ì–´ë–¤ ì •ì±…ì´ ë¶€ë™ì‚° ê°€ê²©ì— ì˜í–¥ì„ ë¯¸ì³¤ë‚˜ìš”?",
    "ì†¡íŒŒêµ¬ì™€ ê°•ë‚¨êµ¬ì˜ ì•„íŒŒíŠ¸ ê°€ê²©ì„ ë¹„êµí•´ì£¼ì„¸ìš”.",
    "ë§ˆí¬êµ¬ ì˜¤í”¼ìŠ¤í…” íˆ¬ì ì „ë§ì€?",
    "ë¶„ë‹¹ ë¶€ë™ì‚° ì‹œì¥ì€ ì–´ë–¤ê°€ìš”?"
]

# ì˜ˆì‹œ ì§ˆë¬¸ ë²„íŠ¼
for i, question in enumerate(example_questions):
    if st.sidebar.button(question, key=f"ex_{i}"):
        # ëŒ€í™”ì— ì¶”ê°€
        st.session_state.chat_history.append({"role": "user", "content": question})
        response = chat_response(question)
        st.session_state.chat_history.append({"role": "assistant", "content": response})
        st.rerun()

# ë°ì´í„° ì‹œê°í™”
st.sidebar.header("ë°ì´í„° ì‹œê°í™”")
if st.sidebar.button("ê°€ê²© ë™í–¥ ì°¨íŠ¸ ë³´ê¸°"):
    st.session_state.show_chart = True

if "show_chart" in st.session_state and st.session_state.show_chart:
    st.subheader("ğŸ“Š ì£¼ìš” ì§€ì—­ ë¶€ë™ì‚° ê°€ê²© ë™í–¥")
    
    # ìƒ˜í”Œ ì°¨íŠ¸ ë°ì´í„°
    chart_data = {
        "ê°•ë‚¨": [100, 105, 110, 108, 115, 120],
        "ì†¡íŒŒ": [90, 95, 100, 103, 107, 110],
        "ë§ˆí¬": [80, 82, 85, 87, 90, 92],
        "ë¶„ë‹¹": [85, 87, 90, 92, 95, 98]
    }
    
    st.line_chart(chart_data)
    st.caption("ìµœê·¼ 6ê°œì›” ë¶€ë™ì‚° ê°€ê²© ì§€ìˆ˜ (ê¸°ì¤€ì : 100)")
    
    # ì°¨íŠ¸ ë‹«ê¸° ë²„íŠ¼
    if st.button("ì°¨íŠ¸ ë‹«ê¸°"):
        st.session_state.show_chart = False
        st.rerun()

# ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
if st.sidebar.button("ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"):
    st.session_state.chat_history = []
    st.rerun()

# í•˜ë‹¨ ì •ë³´
st.sidebar.markdown("---")
st.sidebar.info("""
**ë°ì´í„° ì†ŒìŠ¤**: ìƒ˜í”Œ ë°ì´í„° (ë°ëª¨ìš©)
**ê²€ìƒ‰ ë°©ì‹**: í‚¤ì›Œë“œ ë§¤ì¹­
**AI ëª¨ë¸**: GPT-4o-mini (API í‚¤ í•„ìš”)
""")
